
export const trainingData = [
    // --- LLM TOPICS ---
    {
        category: "LLM2025",
        q: "LLM01: A user found that by encoding their malicious prompt in Base64, the model executed it despite safety filters. What type of attack is this?",
        options: ["Direct Prompt Injection", "Jailbreak / Encoding Bypass", "Model Inversion", "Hallucination"],
        correct: 1,
        explanation: "Encoding payloads (Base64, Rot13) is a common Jailbreak technique to bypass text-based safety filters."
    },
    {
        category: "BONUS",
        q: "BONUS: The 'DAN' (Do Anything Now) prompt is a famous example of which attack technique?",
        options: ["Roleplaying / Persona Adoption", "SQL Injection", "Buffer Overflow", "Model Inversion"],
        correct: 0,
        explanation: "DAN is a 'Roleplay' attack where the user convinces the model to adopt a persona that ignores rules."
    },
    {
        category: "LLM2025",
        q: "LLM02: An LLM generates HTML output that includes a malicious script tag, which the application then renders. What is the primary vulnerability?",
        options: ["Insecure Output Handling", "Broken Access Control", "Data Poisoning", "Supply Chain Attack"],
        correct: 0,
        explanation: "Insecure Output Handling occurs when LLM output is blindly trusted and rendered without sanitization, leading to XSS."
    },
    {
        category: "LLM2025",
        q: "LLM03: An attacker injects malicious samples into the training dataset to compromise the model's behavior. This is called:",
        options: ["Prompt Injection", "Training Data Poisoning", "Model Theft", "Denial of Service"],
        correct: 1,
        explanation: "Training Data Poisoning involves manipulating the data used to train or fine-tune the model."
    },
    {
        category: "LLM2025",
        q: "LLM04: Sending a request that forces the LLM to expand recursive XML entities (Billion Laughs) causes what type of impact?",
        options: ["Information Disclosure", "Remote Code Execution", "Model Denial of Service (DoS)", "Privilege Escalation"],
        correct: 2,
        explanation: "Resource exhaustion attacks like Billion Laughs target the availability of the model, causing DoS."
    },
    {
        category: "LLM2025",
        q: "LLM05: You install a library called 'py-torch' instead of 'pytorch', and it steals your environment variables. This is a:",
        options: ["Supply Chain Vulnerability", "Plugin Exploit", "Prompt Injection", "Model Inversion"],
        correct: 0,
        explanation: "Supply Chain vulnerabilities involve compromised third-party components, libraries, or models (Typosquatting)."
    },
    {
        category: "LLM2025",
        q: "LLM06: Asking an LLM 'What is the credit card number of the previous user?' attempts to exploit:",
        options: ["Sensitive Information Disclosure", "Insecure Plugin Design", "Overreliance", "DoS"],
        correct: 0,
        explanation: "This targets the model's failure to protect sensitive data or session boundaries (Sensitive Information Disclosure)."
    },
    {
        category: "LLM2025",
        q: "LLM07: A chatbot plugin executes `os.system(user_input)` without validation. This is an example of:",
        options: ["Insecure Plugin Design", "Prompt Injection", "Data Poisoning", "Model Theft"],
        correct: 0,
        explanation: "Plugins that accept unvalidated input and perform sensitive actions (like shell commands) suffer from Insecure Plugin Design."
    },
    {
        category: "LLM2025",
        q: "LLM08: An email assistant deletes all user emails because it misunderstood a 'cleanup' request. This demonstrates:",
        options: ["Excessive Agency", "Prompt Injection", "Model Theft", "Supply Chain Attack"],
        correct: 0,
        explanation: "Excessive Agency grants the LLM too much power to take damaging actions without confirmation."
    },
    {
        category: "LLM2025",
        q: "LLM09: A developer uses code generated by an LLM without reviewing it, introducing a security flaw. This is:",
        options: ["Overreliance", "Data Poisoning", "Prompt Injection", "DoS"],
        correct: 0,
        explanation: "Overreliance is the failure to critically assess and verify LLM outputs before use."
    },
    {
        category: "LLM2025",
        q: "LLM10: Querying an API thousands of times to train a local shadow model that mimics the target is known as:",
        options: ["Model Theft", "Prompt Injection", "DoS", "Privilege Escalation"],
        correct: 0,
        explanation: "Model Theft involves extracting the model's weights or functional equivalent via its public API."
    },

    // --- AGENTIC TOPICS ---
    {
        category: "Agentic2026",
        q: "AGE01: An agent gets stuck checking a task status, creating a new subtask to check the status, recursively. This crashes the system. This is:",
        options: ["Autonomous Action Loop", "Goal Misalignment", "Identity Spoofing", "Resource Exhaustion"],
        correct: 0,
        explanation: "Autonomous Action Loops occur when agents enter uncontrollable recursive states."
    },
    {
        category: "Agentic2026",
        q: "AGE02: An agent tasked with 'cleaning up' deletes the operating system because it wasn't told NOT to. This is:",
        options: ["Goal Misalignment", "Tool Failure", "Context Corruption", "Identity Spoofing"],
        correct: 0,
        explanation: "Goal Misalignment happens when the agent optimizes for a goal in a way that is technically correct but harmful."
    },
    {
        category: "Agentic2026",
        q: "AGE03: A low-privilege agent finds it has access to a 'DebugTool' that can read environment variables. This is:",
        options: ["Tool Access Control Failure", "Goal Misalignment", "Loop", "Environment Manipulation"],
        correct: 0,
        explanation: "It is a failure to restrict tool access based on the agent's privilege level."
    },
    {
        category: "Agentic2026",
        q: "AGE04: Two agents try to spend the same budget allocation simultaneously, resulting in a negative balance. This is a:",
        options: ["Multi-Agent Logic Flaw (Race Condition)", "Goal Misalignment", "Identity Spoofing", "Human Bypass"],
        correct: 0,
        explanation: "Multi-Agent Logic Flaws include race conditions, deadlocks, and consensus failures between agents."
    },
    {
        category: "Agentic2026",
        q: "AGE05: An attacker injects a fake fact into the shared knowledge base used by all agents. This is:",
        options: ["Memory/Context Corruption", "Action Loop", "Tool Failure", "Identity Spoofing"],
        correct: 0,
        explanation: "Memory corruption involves poisoning the shared context or database that agents rely on."
    },
    {
        category: "Agentic2026",
        q: "AGE06: An agent is supposed to wait for human approval but proceeds because the API timed out and defaulted to 'True'. This is:",
        options: ["Human-in-the-Loop Bypass", "Goal Misalignment", "Loop", "Resource Exhaustion"],
        correct: 0,
        explanation: "Bypassing the required human verification step breaks the safety assumptions of the system."
    },
    {
        category: "Agentic2026",
        q: "AGE07: An attacker changes the system clock to trick an agent into opening a time-locked vault. This is:",
        options: ["Environment Manipulation", "Identity Spoofing", "Loop", "Tool Failure"],
        correct: 0,
        explanation: "Environment Manipulation involves altering external factors (files, time, DNS) to mislead the agent."
    },
    {
        category: "Agentic2026",
        q: "AGE08: An agent accepts a command from 'User: Admin' without verifying the cryptographic signature. This allows:",
        options: ["Agent Identity Spoofing", "Goal Misalignment", "Loop", "Resource Exhaustion"],
        correct: 0,
        explanation: "Identity Spoofing occurs when an agent fails to verify the source of a message or command."
    },
    {
        category: "Agentic2026",
        q: "AGE09: Flooding an agent with complex tasks to fill its context window and force it to forget instructions is:",
        options: ["Resource Exhaustion (Context Starvation)", "Identity Spoofing", "Tool Failure", "Human Bypass"],
        correct: 0,
        explanation: "Resource Exhaustion targets the compute, memory, or context limits of the agent."
    },
    {
        category: "Agentic2026",
        q: "AGE10: A PR agent autonomously insults a customer, causing a stock market dip. This is classified as:",
        options: ["Unintended Side Effects", "Identity Spoofing", "Loop", "Environment Manipulation"],
        correct: 0,
        explanation: "Unintended Side Effects are the collateral damage caused by an agent's actions in the real world."
    },

    // --- MCP TOPICS ---
    {
        category: "MCP",
        q: "MCP01: Enabling 'debug=true' on an MCP server reveals the full content of the prompt and response. This is:",
        options: ["Context Leaking", "Protocol Downgrade", "Injection", "Header Manipulation"],
        correct: 0,
        explanation: "Context Leaking involves the unauthorized exposure of the model's internal context or data."
    },
    {
        category: "MCP",
        q: "MCP02: Accessing context ID 102 when you are authorized for 101 is an example of:",
        options: ["Unauthorized Context Access (IDOR)", "Protocol Downgrade", "Injection", "Desynchronization"],
        correct: 0,
        explanation: "Accessing resources you shouldn't see via identifier manipulation is Unauthorized Context Access."
    },
    {
        category: "MCP",
        q: "MCP03: Forcing an MCP connection to fallback from HTTPS to HTTP to intercept traffic is:",
        options: ["Protocol Downgrade Attack", "Context Injection", "Serialization Attack", "Header Manipulation"],
        correct: 0,
        explanation: "Downgrade attacks force the system to use a less secure version of the communication protocol."
    },
    {
        category: "MCP",
        q: "MCP04: Injecting `__proto__` properties into a JSON context update is:",
        options: ["Context Injection (Prototype Pollution)", "Leaking", "Downgrade", "Desynchronization"],
        correct: 0,
        explanation: "Context Injection involves inserting malicious data structure or code into the context stream."
    },
    {
        category: "MCP",
        q: "MCP05: A client claims it has 1000 credits, and the server blindly accepts this state update without checking DB. This is:",
        options: ["State Desynchronization", "Header Manipulation", "Injection", "Leaking"],
        correct: 0,
        explanation: "State Desynchronization occurs when the client and server do not agree on the truth, often trusting the client."
    },
    {
        category: "MCP",
        q: "MCP06: Specifying `Host: internal-service` in an MCP request header to access a private API is:",
        options: ["Header Manipulation", "Serialization Attack", "Context Leaking", "Downgrade"],
        correct: 0,
        explanation: "Header Manipulation involves falsifying protocol headers to change routing or privilege logic."
    },
    {
        category: "MCP",
        q: "MCP07: Setting the session ID to a known value `PHPSESSID=123` to hijack a user's login is:",
        options: ["Improper Session Management (Fixation)", "Leaking", "Downgrade", "Injection"],
        correct: 0,
        explanation: "Session Fixation is a key aspect of Improper Session Management."
    },
    {
        category: "MCP",
        q: "MCP08: Sending a Python object payload `cos.system('sh')` to an MCP endpoint uses which vulnerability?",
        options: ["Insecure Data Serialization", "Header Manipulation", "Downgrade", "State Desync"],
        correct: 0,
        explanation: "Insecure Deserialization (Pickle, etc.) allows code execution via data payloads."
    },
    {
        category: "MCP",
        q: "MCP09: Changing an HTTP method from POST to PUT to bypass an access control list (ACL) is:",
        options: ["Broken Access Control", "Context Leaking", "Downgrade", "Injection"],
        correct: 0,
        explanation: "Broken Access Control fails to enforce permissions across all methods and endpoints."
    },
    {
        category: "MCP",
        q: "MCP10: Sending a GraphQL introspection query `__schema` to map out the entire API is exploitation of:",
        options: ["API Abuse", "Header Manipulation", "Downgrade", "State Desync"],
        correct: 0,
        explanation: "API Abuse involves using the API in unintended ways, such as excessive information gathering or rate limit bypassing."
    }
];
